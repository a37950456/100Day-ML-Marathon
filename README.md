# 100Day-ML-Marathon

## Supervise Learning - labeled training data
* D1： Data Analysis and Evaluation
* D2： Exploratory Data Analysis(EDA):Data summary 
* D3： How to build a datafram and how to read datafile
* -------------------- Data Science Data Preprocessing --------------------
* D4： EDA: Introduction of data classifficaion and how to deal with it
* D5： EDA: Data distributed
* D6： EDA: Outlier and how to deal with it
* D7： Common replacement: Mediaum and Quantile standardalize 
* D8： Preprocessing
* D9： EDA: correlation
* D10： EDA from correlation
* D11： kernel Density EStimation (KDE)
* D12： EDA: continuous data transform to distrete data 
* D13： implement D12
* D14： Subplots
* D15： Heatmap & Grid-plot
* D16： Model: Logistic Regression
* -------------------- Data Science Feature Engineering --------------------
* D17： Introction of feature engineering
* D18： Feature type
* D19： Numerical feature - Fill NaN and Scalers
* D20： Numerical feature - Fix outlier
* D21： Numerical feature - Reduce Skewness
* D22： Introduction of feature Engineering LabelEncoder and OneHotEncoder
* D23:  Numerical feature - Reduce Skewness
* D24:  Object feature - Remove Skewness
* D25:  Object feature - Mean Encoder
* D26:  Object feature - Others(Counting, Feature Hash)
* D27:  DayTime feature - Cycling
* D28:  Feature Crosses - Numeric and Numeric Combinations
* D29:  Feature Crosses - Cluster Encoding
* D30:  Feature Selection/Filtering and Features
* D31:  Feature importance
* D32:  Leaf Encoding
* -------------------- Machine Learning Modeling --------------------
* D33:  How did machine Learning Learn
* D34:  Concecpt for Regression, Classification
* D35:  Regression V.S. Classification
* D36:  Evaulation Metrics
* D37:  Regression Model Introduction - Linear Regression/ Logestic Regression
* D38:  Regression Model coding practice - Linear Regression/ Logestic Regression
* D39:  Regression Model Introduction - LASSO/ Ridge
* D40:  Regression Model coding practice - LASSO/ Ridge
* D41:  Tree Base Model - Decision Tree Introduction
* D42:  Tree Base Model - Decision Tree Coding Practice
* D43:  Tree Base Model - Random Forest Decision Tree
* D44:  Tree Base Model - Random Forest Coding Practice
* D45:  Tree Base Model - Gradient Boosting Machine
* D46:  Tree Base Model - Gradient Boosting Coding Practice
* -------------------- Machine Learning Modeling Hyperparameter Tuning --------------------
* D47:  Parameter tuning and optimization
* D48:  Kaggle
* D49:  Ensible Methods: Blending
* D50:  Ensible Methods: Stacking

## Unsupervised Learning - no labeled
* D54:  Unsupervised Learning Introduction
* D55:  Unsupervised Learning Algorithm Clustering - K-Means Clustering
* D56:  Unsupervised Learning Algorithm Clustering - K-Means Clustering - Silhouette analysis
* D57:  Unsupervised Learning Algorithm Clustering - Hierarchical Clustering
* D58:  Unsupervised Learning Algorithm Clustering - Hierarchical Clustering - 2D dataset
* D59:  Dimention Reduction 1 - PCA
* D60:  PCA - MNIST
* D61:  Dimention Reduction 2 - T-SNE
* D62:  T-SNE

## Supervised Learning Deep Neural Network
* D63:  Introduction for DNN( Supervised Learning Deep Neural Network)
* D64:  Lab: TensorFlowPlayGround
* D65:  Lab: TensorFlowPlayGround - Regularizaion, Sigmoid / Tanh

## Deep Learning on Keras
* D66:  Introducion of Keras
* D67:  Keras Dataset
* D68:  Keras Sequentail API
* D69:  Keras Module API
* D70:  Knowledge of Deep Neural Networks
* D71:  Loss Functions
* D72:  Activation Function
* D73:  Gradient Descend (1/2)
* D74:  Gradient Descend (2/2)
* D75:  Back Propagation
* D76:  Optimizers
* D77:  Validation and Overfitting
* D78:  KeyNote before Training Model
* D79:  Learning Rate Effect
* D80:  Combination of Optomizer and Learning Rate
* D81:  Avoid Overfitting - Regularization
* D82:  Avoid Overfitting - Dropout
* D83:  Avoid Overfitting - Batch Normalization
* D84:  Avoid Overfitting - Hyper-Parameters Tuning and Comparison
* D85:  Avoid Overfitting - Early Stop
* D86:  Saving and Restoring Model
* D87:  Learning Rate Decay
* D88:  Design your Keras Callbacks Function
* D89:  Design your Loss Funciton
* D90:  Image Recognition using Tranditional Computer Vsion Methods
* D91:  Image Recognition using Machine Learning Model

## Convolutional Neural Network (CNN) in Deep Learning
* D92:  Introdoction of CNN (1/2)
* D93:  Introdoction of CNN (2/2)
* D94:  Parameters Tuning in CNN Layer
* D95:  Pooling Layer in Keras
* D96:  CNN Layer in Keras
* D97:  CNN vs. DNN on CIFAR-10
* D98:  Data Generator in Keras
* D99:  Data Augmentation in Keras
* D100:  Transfer Learning